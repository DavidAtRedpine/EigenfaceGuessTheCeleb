{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBnaMELsW65Y5ztQik4Nvd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidAtRedpine/EigenfaceGuessTheCeleb/blob/main/EigenfaceGuessTheCeleb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Required Libraries"
      ],
      "metadata": {
        "id": "sgQTFCHBQOlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets pyarrow fsspec pillow matplotlib scikit-learn huggingface_hub\n",
        "\n",
        "from google.colab import files\n",
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from huggingface_hub import hf_hub_download"
      ],
      "metadata": {
        "id": "57EEwKgCQRji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Dataset from Hugging Face"
      ],
      "metadata": {
        "id": "u79pAkpzQeaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download the Parquet file from the correct subdirectory\n",
        "parquet_file = hf_hub_download(repo_id=\"theneuralmaze/celebrity_faces\", filename=\"data/train-00000-of-00001.parquet\", repo_type=\"dataset\")\n",
        "\n",
        "# Confirm the file was downloaded\n",
        "print(f\"Downloaded file: {parquet_file}\")\n",
        "\n",
        "# Load the Parquet file as a dataset\n",
        "dataset = load_dataset(\"parquet\", data_files=parquet_file, split=\"train\")\n",
        "\n",
        "# Confirm the dataset structure\n",
        "print(dataset)\n",
        "\n",
        "# Extract processed data\n",
        "image_data = np.stack(dataset['image'])  # Images as flattened arrays\n",
        "celebrity_names = np.array(dataset['label'])  # Labels (celebrity names)\n",
        "\n",
        "print(f\"Processed {image_data.shape[0]} celebrity images with {image_data.shape[1]} pixels each.\")\n",
        "\n",
        "print (\"Celebrities include...\")\n",
        "# range from 0 to length of celebrity_names or 20, whichever is smaller\n",
        "for i in range(min(20, len(celebrity_names))):\n",
        "  print (celebrity_names[i])\n"
      ],
      "metadata": {
        "id": "KsfclnzgQkct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute Eigenfaces using PCA"
      ],
      "metadata": {
        "id": "ZifiQitiVqC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_components = 50  # Number of principal components (eigenfaces)\n",
        "\n",
        "def preprocess_image(example):\n",
        "    image = example['image'].convert('L')  # Convert to grayscale\n",
        "    resized_image = image.resize((100, 100))  # Force resize to 100x100\n",
        "    return {'image_array': np.array(resized_image).flatten() / 255.0}  # Flatten and normalize\n",
        "\n",
        "# Apply preprocessing\n",
        "dataset = dataset.map(preprocess_image)\n",
        "\n",
        "# Re-check image data\n",
        "image_data = np.stack(dataset['image_array'])  # Flattened arrays\n",
        "print(\"Shape of image_data:\", image_data.shape)  # Should be (N, 10000)\n",
        "\n",
        "mean_face = np.mean(image_data, axis=0)\n",
        "centered_data = image_data - mean_face\n",
        "centered_data = centered_data.reshape(centered_data.shape[0], -1)\n",
        "\n",
        "pca = PCA(n_components=num_components)\n",
        "pca.fit(centered_data)\n",
        "eigenfaces = pca.transform(centered_data)\n"
      ],
      "metadata": {
        "id": "gL9il-ZEVt_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the mean face and some eigenfaces"
      ],
      "metadata": {
        "id": "flZ2aDUhVyIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(mean_face.reshape((100, 100)), cmap='gray')\n",
        "plt.title(\"Mean Face\")\n",
        "plt.axis('off')\n",
        "\n",
        "for i in range(5):  # Display the first 5 eigenfaces\n",
        "    plt.subplot(2, 5, i+6)\n",
        "    plt.imshow(pca.components_[i].reshape((100, 100)), cmap='gray')\n",
        "    plt.title(f\"Eigenface {i+1}\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hcU7nuPYV1T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Recognition System"
      ],
      "metadata": {
        "id": "zAW8dCCehanL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "face_projections = pca.transform(centered_data)"
      ],
      "metadata": {
        "id": "CY9qZSblhcR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the Recognition System"
      ],
      "metadata": {
        "id": "NVyP1-7_hhB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()  # Opens a dialog to upload an image file\n",
        "\n",
        "# Load and preprocess the test image\n",
        "uploaded_image_path = list(uploaded.keys())[0]  # Get the uploaded file's name\n",
        "test_image = Image.open(uploaded_image_path).convert('L')  # Convert to grayscale\n",
        "test_image = test_image.resize((100, 100))  # Resize to match training images\n",
        "test_face = np.array(test_image).flatten() / 255.0  # Normalize and flatten\n",
        "\n",
        "def predict_celebrity(new_face, face_projections, celebrity_names, mean_face, pca, k=1):\n",
        "    new_face = new_face.flatten() - mean_face  # Preprocess the new face\n",
        "    new_projection = pca.transform(new_face.reshape(1, -1))  # Project into eigenface space\n",
        "    distances = pairwise_distances(new_projection, face_projections, metric='euclidean')\n",
        "    closest_indices = np.argsort(distances[0])[:k]\n",
        "    closest_celebs = celebrity_names[closest_indices]\n",
        "    return closest_celebs, distances[0, closest_indices]\n",
        "\n",
        "# Test the Recognition System\n",
        "predicted_celeb, similarity_scores = predict_celebrity(test_face, face_projections, celebrity_names, mean_face, pca)\n",
        "\n",
        "print(f\"Predicted Celebrity: {predicted_celeb[0]} with similarity score {similarity_scores[0]}\")\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(test_face.reshape((100, 100)), cmap='gray')\n",
        "plt.title(f\"Predicted: {predicted_celeb[0]}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rE_MqkBiq6Lm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}